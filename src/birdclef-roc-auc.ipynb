{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339e7801",
   "metadata": {
    "_cell_guid": "4cf02a6f-b7e9-4360-892d-b1a50793eb12",
    "_uuid": "2a1239f3-55fc-4dbb-9d3a-e90bfffa038c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-15T22:50:33.185023Z",
     "iopub.status.busy": "2024-03-15T22:50:33.184249Z",
     "iopub.status.idle": "2024-03-15T22:50:35.319281Z",
     "shell.execute_reply": "2024-03-15T22:50:35.317964Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.142194,
     "end_time": "2024-03-15T22:50:35.322051",
     "exception": false,
     "start_time": "2024-03-15T22:50:33.179857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "\n",
    "import kaggle_metric_utilities\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Version of macro-averaged ROC-AUC score that ignores all classes that have no true positive labels.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    if not pandas.api.types.is_numeric_dtype(submission.values):\n",
    "        bad_dtypes = {x: submission[x].dtype  for x in submission.columns if not pandas.api.types.is_numeric_dtype(submission[x])}\n",
    "        raise ParticipantVisibleError(f'Invalid submission data types found: {bad_dtypes}')\n",
    "\n",
    "    solution_sums = solution.sum(axis=0)\n",
    "    scored_columns = list(solution_sums[solution_sums > 0].index.values)\n",
    "    assert len(scored_columns) > 0\n",
    "\n",
    "    return kaggle_metric_utilities.safe_call_score(sklearn.metrics.roc_auc_score, solution[scored_columns].values, submission[scored_columns].values, average='macro')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 154891491,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "BirdCLEF-2025-WeerwaarT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.927674,
   "end_time": "2024-03-15T22:50:36.147317",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-15T22:50:30.219643",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
